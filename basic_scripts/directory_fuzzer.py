'''
This is a Python script that performs a basic directory and file brute-forcing attack on a given target website. 
It does this by making HTTP GET requests to various URLs constructed by concatenating the target URL with different 
combinations of words and file extensions, and checking the HTTP status code of the response to see if the URL is valid.

The script starts by importing the necessary libraries: requests, queue, and threading. It then defines some variables at the top:

target: the URL of the target 
wordlist: the file path of the wordlist to use for the brute-force attack
resume: (optional) a word to start the attack from. If this variable is set, the script will start the attack from the first word 
in the wordlist that matches this word, rather than starting at the beginning of the wordlist.
user_agent: a string containing the user agent to use when making requests
headers: a dictionary containing HTTP headers to include in the requests
threads: the number of threads to use for the attack

The script then defines a function create_wordlist() which takes a wordlist file path as input, reads the words from the file, 
and returns a queue containing the words. If the resume variable is set, the function will start the queue from the first word 
that matches the resume value.

The dir_fuzzer() function takes a word queue and an optional list of file extensions as input. It iterates over the words in the queue, 
constructing a list of URL paths to try. If the word does not contain a period (i.e. it is not a file name), it is assumed to be a 
directory name and a forward slash is added to the beginning and end of the word to create a URL path like /word/. If the word does 
contain a period, it is assumed to be a file name and a forward slash is added only to the beginning to create a URL path like /word. 
If the extensions argument is provided, the function will try each extension with each word.

For each URL path in the list, the function makes an HTTP GET request to the target website with the path appended to the end of the target URL. 
If the status code of the response is 200, it means the URL is valid and the function adds the URL and the original path to a list of valid URLs.

Finally, the script creates a word queue using the create_wordlist() function and starts threads number of threads, each of which runs the 
dir_fuzzer() function with the word queue as an argument. This allows the brute-forcing attack to be performed concurrently by multiple threads, 
potentially speeding up the process.
'''


from requests.exceptions import ProxyError
import requests
import queue
import threading

target = "https://www.example.com"
wordlist = "/usr/share/wordlists/dirbuster/directory-list-2.3-medium.txt"
resume = None
user_agent = "Mozilla/5.0 (X11; Linux x86_64; rv:19.0) Gecko/20100101 Firefox/19.0"
headers = {}
headers['user-agent'] = user_agent
threads = 50

def create_wordlist(wordlist):
	fd = open(wordlist, "rb")
	raw_words = fd.readlines()
	fd.close()
	
	found_resume = False
	words = queue.Queue()
	
	for word in raw_words:
		word = word.rstrip()
		word = word.decode('utf-8')
		if resume:
			if found_resume:
				words.put(word)
			else:
				if word == resume:
					found_resume = True
					print("Resuming wordlist from: {}".format(resume))
		else:
			words.put(word)
	return words
	
def dir_fuzzer(word_queue, extensions=None):
	while not word_queue.empty():
		attempt = word_queue.get()
		attempt_list = []
		
		# check to see if there is a file extension; if not,
		# it's a directory path we're brute forcing
		if "." not in str(attempt):
			attempt_list.append("/{}/".format(attempt))
		else:
			attempt_list.append("/{}".format(attempt))
			
		# if we want to bruteforce extensions
		if extensions:
			for extension in extensions:
				attempt_list.append("{}{}".format(attempt, extension))
				
		# iterate over the list of attempts
		valid = []
		for attempt in attempt_list:
			url = "{}{}".format(target, requests.utils.requote_uri(attempt))
			try:
				r = requests.get(url, headers=headers)
			
				if r.status_code == 200:
					print("Found URL {}".format(url))
					valid.append([url, attempt])
			except ProxyError:
				print("Failed: {}".format(attempt))
				
	return valid


word_queue = create_wordlist(wordlist)	
for i in range(threads):
	t = threading.Thread(target=dir_fuzzer, args=(word_queue,))
	t.start()
